{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee656cc5-16ed-41eb-915c-5b47d7d531e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Case **Statement**\n",
    "- To evaluate list of conditions and choose a result path according to the matching condition,** When().Otherwise()** function in pyspark can be used\n",
    "- This is similoar to case or switch statment in other programming languags\n",
    "- When no condition is maching, Otherwise result path would be chosen\n",
    "\n",
    "**Syntax:**\n",
    "\n",
    "df.withColumn(\"New or existing column\", when(condition1, Result1)\n",
    "                                          .when(condition2, Result2)\n",
    "                                          .when(conditionN, ResultN)\n",
    "                                          .otherwise(Result))\n",
    "\n",
    "df.withColumn(\"New or existing column\", expr(\"CASE WHEN condition1 THEN Result1\" +\n",
    "                                          \"WHEN condition2 THEN Result2\" +\n",
    "                                          \"WHEN conditionN THEN ResultN\" +\n",
    "                                          \"ELSE Result END\"))\n",
    "\n",
    "To Combile multiple conditions: '&' for AND; '|' for OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9dfed09f-3477-4cac-9643-28853af015eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Create Sample Datafrmae**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9244da9b-ff65-45f3-b02c-c93b0f2fc628",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_student = [\n",
    "    (\"Raja\", \"Science\", 80, \"P\", 90),\n",
    "    (\"Rakesh\", \"Maths\", 90, \"P\", 70),\n",
    "    (\"Rama\", \"English\", 20, \"F\", 80),\n",
    "    (\"Ramesh\", \"Science\", 45, \"F\", 75),\n",
    "    (\"Rajesh\", \"Maths\", 30, \"F\", 50),\n",
    "    (\"Raghav\", \"Maths\", None, \"NA\", 70)\n",
    "    ]\n",
    "\n",
    "Schema = [\"Name\", \"Subject\", \"Marks\", \"Status\", \"Attendance\"]\n",
    "df = spark.createDataFrame(data  = data_student, schema = Schema)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24603f1f-99f2-4de7-8798-e25a5b018b21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Update the Existing Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d95fbe4f-1b62-40e4-b4d9-dd52a199acdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df1 = df.withColumn(\"Status\", when(df.Marks >= 50, \"Pass\")\n",
    "                    .when(df.Marks < 50, \"Fail\")\n",
    "                    .otherwise(\"Absentee\"))\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d59e3ad2-2c4e-4da1-a4da-8fd0bc9e2902",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Create a New Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9c4f62b-fc89-47e0-962a-d6e607bd3676",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df2 = df.withColumn(\"New_Status\", when(df.Marks >= 50, \"Pass\")\n",
    "                    .when(df.Marks < 50, \"Fail\")\n",
    "                    .otherwise(\"Absentee\"))\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9513ebeb-a581-4290-9943-6a677d7b4401",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Another Syntax Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3ec6a76-c42f-46cf-b17c-570e2b0c5bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "df3 = df.withColumn(\"New_Status\", expr(\"CASE WHEN Marks >= 50 THEN 'Pass' \" +\n",
    "                                       \"WHEN Marks < 50 THEN 'Fail' \" +\n",
    "                                       \"ELSE 'Absentee' END\"))\n",
    "\n",
    "display(df3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c91cb9e-7bc5-4240-bdec-6f7a0b8b6c43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## **Multi Conditions using AND and OR Operators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44ba276c-5574-4c36-bfd0-c92bf8480dac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "df4 =df.withColumn(\"Grade\", when((df.Marks >= 80) & (df.Attendance >= 80), \"Distinction\")\n",
    "                    .when((df.Marks >= 50) & (df.Attendance >= 50), \"Good\")\n",
    "                    .otherwise(\"Average\"))\n",
    "\n",
    "display(df4)\n",
    "\n",
    "df5 =df.withColumn(\"Grade\", when((df.Marks >= 80) | (df.Attendance >= 80), \"Distinction\")\n",
    "                    .when((df.Marks >= 50) | (df.Attendance >= 50), \"Good\")\n",
    "                    .otherwise(\"Average\"))\n",
    "\n",
    "display(df5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "12 - When Otherwise Function",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
