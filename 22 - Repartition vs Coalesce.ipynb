{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa140e13-d91c-44a4-9f39-ee2f33b807c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Need of Partition Strategy\n",
    "\n",
    "- Adopitng best partition strategy is designing best performance in spark application\n",
    "- The right number of partitions created based on number of cores boosts the performance. If not, hits the performance\n",
    "- Evenly distibuted partition improves the performancem unevenly distributed performance hits the performance\n",
    "- Lets say only one partition is created with size of 500 MB in a worker mode with 16 cores. One partition can't be shared among cores. \n",
    "- So one core would be processing 500 MB data where 15 cores are kept idle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9214d11f-253c-4bbd-a664-e99f6c47e295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Default Partitions for RDD/Dataframe\n",
    "\n",
    "- The parameter **sc.defaultParallelism** determines the nubmer of partitions when creating data within saprk\n",
    "- Default value is 8 so it creates 8 partition by default\n",
    "- When reading data from external system, partitions are created based on parameter **spark.sql.files.maxPartitionBytes**\n",
    "- which is by default 128 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f3570bc-de46-45cc-81e2-17f1b2bac799",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Repartition\n",
    "\n",
    "- Function repartition is used to increase or decrease partitions in Spark\n",
    "- Repartition always shuffle the data build new partitions from scratch\n",
    "- Repartition results in almost equal sized partitions\n",
    "- Due to full shuffle, It is not good for performance in some use cases. But as it creates equal sized partitions, \n",
    "- good for performance in some use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d58ab3c9-4efd-4d02-a813-1253fa8b70fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Coalesce\n",
    "- Coalesce function only reduces the number of partitions\n",
    "- Coalesce doesn't require a full shuffle\n",
    "- Coalesce combine few partitions or shuffles data only from few partitions thus avoiding full shuffle\n",
    "- Due to partition merge, It produces uneven size of partitions\n",
    "- Since full shuffle is avoided, Coalesce is more performant than repartition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "992e20e1-ed5a-4091-b01c-66a0a8cbdd37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "253ac313-5991-490d-ad00-48b8bcae72ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bab22fd5-493a-4eeb-81d6-2385535dd09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"128MB\")\n",
    "spark.conf.get(\"spark.sql.files.maxPartitionBytes\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "22 - Repartition vs Coalesce",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
