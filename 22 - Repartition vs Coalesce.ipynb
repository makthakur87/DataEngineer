{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa140e13-d91c-44a4-9f39-ee2f33b807c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Need of Partition Strategy\n",
    "\n",
    "- Adopitng best partition strategy is designing best performance in spark application\n",
    "- The right number of partitions created based on number of cores boosts the performance. If not, hits the performance\n",
    "- Evenly distibuted partition improves the performancem unevenly distributed performance hits the performance\n",
    "- Lets say only one partition is created with size of 500 MB in a worker mode with 16 cores. One partition can't be shared among cores. \n",
    "- So one core would be processing 500 MB data where 15 cores are kept idle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9214d11f-253c-4bbd-a664-e99f6c47e295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Default Partitions for RDD/Dataframe\n",
    "\n",
    "- The parameter **sc.defaultParallelism** determines the nubmer of partitions when creating data within saprk\n",
    "- Default value is 8 so it creates 8 partition by default\n",
    "- When reading data from external system, partitions are created based on parameter **spark.sql.files.maxPartitionBytes**\n",
    "- which is by default 128 MB\n",
    "\n",
    "![](Images/22/22 Default Partitions.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f3570bc-de46-45cc-81e2-17f1b2bac799",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Repartition\n",
    "\n",
    "- Function repartition is used to increase or decrease partitions in Spark\n",
    "- Repartition always shuffle the data build new partitions from scratch\n",
    "- Repartition results in almost equal sized partitions\n",
    "- Due to full shuffle, It is not good for performance in some use cases. But as it creates equal sized partitions, \n",
    "- good for performance in some use case\n",
    "\n",
    "![](Images/22/22 Repartitions.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d58ab3c9-4efd-4d02-a813-1253fa8b70fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Coalesce\n",
    "- Coalesce function only reduces the number of partitions\n",
    "- Coalesce doesn't require a full shuffle\n",
    "- Coalesce combine few partitions or shuffles data only from few partitions thus avoiding full shuffle\n",
    "- Due to partition merge, It produces uneven size of partitions\n",
    "- Since full shuffle is avoided, Coalesce is more performant than repartition\n",
    "\n",
    "![](Images/22/22 Coalesce.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "992e20e1-ed5a-4091-b01c-66a0a8cbdd37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Check Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "253ac313-5991-490d-ad00-48b8bcae72ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sc.defaultParallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bab22fd5-493a-4eeb-81d6-2385535dd09b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", \"128MB\")\n",
    "#spark.conf.get(\"spark.sql.files.maxPartitionBytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ac30d54-7c55-4ed3-9c44-c3fccead4afd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Generating Data within Spark Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d06fcb03-9a63-416f-b243-e4225486d1c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df = spark.createDataFrame(range(10), IntegerType())\n",
    "\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98a40bf5-5fff-4ece-9402-6c07ae64f1da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Verify the Data within All Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efea71d7-c8b3-41c1-97f8-b4895fc6bb14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c5f0c2f-2cbc-405a-89ef-53643c56a265",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read External File in Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "920237b6-0e5f-46fb-8fdc-cb58832b8d43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"/Volumes/workspace/default/mandy/baby_names/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "643953c7-5b15-4e88-9986-e8709352e427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/Volumes/workspace/default/mandy/baby_names/\")\n",
    "df.rdd.getNumPartitions()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "22 - Repartition vs Coalesce",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
