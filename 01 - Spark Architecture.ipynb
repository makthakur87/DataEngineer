{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfab5081-6ee7-4abe-8e6d-8d5a1bb616d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### What is Spark\n",
    "- Spark is an open source distributed computing engine. we use it for processing and analysing a large amount of data. Like Hadoop, Spark also works in distributed nature but differs in in-memory processing.\n",
    "- compare to Hadoop or traditional systems, 100 times faster in memory and 10 times faster in disc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98729e5a-2ac9-4ef9-b90c-b7578e516008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### How it handle the processes at lightning speed?\n",
    "- It's lightning speed is from in-memory and parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e6911e4-b9fa-4e9f-a5c0-815d8a7a46e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Architecture\n",
    "- Spark has well designed layered architecture. It follows master/slave concept. That is driver and worker concept. \n",
    "- Between driver and worker layer comes cluster manager layer. These layers driver, worker and cluster manager and desinged well within its boundry and loosley coupled to each other.\n",
    "\n",
    "![](Images/01/01 Architecture.jpg)\n",
    "\n",
    "![](Images/01/01 Executor.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3de16b5-e82d-46f0-95c0-b7bb17a16491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Lifecycle of Spark Application\n",
    "User Submit Application -> Driver initiates Spark Session -> DAG creates Llogical plan -> Task Executor requests for resources from Cluster Manager -> Cluster Manager allocates resources to execute task -> Driver establishes connection with worker and assigns task -> Worker executes the task and returns results to driver -> Driver returns the results to User -> Application comes to end\n",
    "\n",
    "DAG (Directed Acyclic Graph) - It creates the logical plans for all the transformation\n",
    "\n",
    "![](Images/01/01 Lifecycle.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fa1fbd2-78e1-440e-abfd-24582099ab09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Spark Attributes\n",
    "- Scalable\n",
    "- Fault-Tolerant\n",
    "- Polyglot\n",
    "- Real Time\n",
    "- Speed\n",
    "- Rich Libraries\n",
    "\n",
    "![](Images/01/01 Spark Attributes.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c13fa837-57d6-4afb-b583-e40c549f11eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Terminologies\n",
    "- **Driver and Worker Process** - These are nothing but JVM process. Within one Worker Node, there could be multiple Executors. Each Executor runs its own JVM process.\n",
    "- **Applicaton** - It could be single command or combination of multiple notebooks with complex logic. When code is submitted to spark for execution, Application starts.\n",
    "- **Jobs** - When an application is submitted to Spark, Driver process converts the code into job.\n",
    "- **Stage** - Jobs are divided into stages. if the application code demands shuffling the data across nodes, new stage is created. Number of stages are determined by number of shuffling operations. Join is example of Shuffling operation.\n",
    "- **Tasks** - Stages are further divided into multiple tasks. In a stage, all the tasks would execute same logic. Each task will process 1 partition at a time. So number of partition in the distributed cluster determines the number of tasks in each stage\n",
    "\n",
    "![](Images/01/01 Spark Application.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ed6f002-b038-4c00-b1b4-fb41bcaeb53c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Terminologies\n",
    "- **Transformation** - transforms the input RDD and creates new RDD. Until action is called, Transformations are evaluated lazily.\n",
    "- **DAG** - Directed Acyclic Graph keeps track of all transformation. For each transformation, logical plan is created and lineage graph is maintained by DAG.\n",
    "- **Acttion** - When data output is needed for developer or for storage purpose, Action is called. Action would be executed based on DAG and processes the actual data.\n",
    "- **RDD** - Resilient Distributed Dataset is basic data structure of spark. When spark reads or creates data, it creates RDD which is distributed across nodes in the form of partition.\n",
    "- **Executor** - Each worker node can consists of many executors. It can be configured by spark settings\n",
    "- **Partition** - RDD/Dataframe is stored in-memory of cluster in the form of partition.\n",
    "- **Core** - Each Executor can consists of multiple cores. This is configurable by spark settings. Each core (if Single Thread) can process one task at a time.\n",
    "- **On-Heap Memory** - The executor memory that lies within JVM process managed JVM.\n",
    "- Off-Heap Memory - The Executor memory that lies outside JVM process managed by OS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eca3fe21-cb1d-408a-b624-6be0b0978285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Spark Libraries\n",
    "\n",
    "![](Images/01/01 Spark Libraries.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03c10070-3cf3-41e3-a221-8cc194b6840b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Driver Node Architecture\n",
    "\n",
    "![](Images/01/01 Driver Node Architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20bc4038-5f0d-4630-9d28-467730370340",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Worker Node Architecture\n",
    "\n",
    "![](Images/01/01 Worker Node Architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49fee725-69c9-4fc5-bc1f-fe793d7c97a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Memory Node Architecture\n",
    "\n",
    "![](Images/01/01 Memory Architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e69154d-a48f-4b20-a4c1-f12b4d4ab6cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Read Single CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd7190d5-1c06-45b0-9135-dcf07a40f25b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", True).option(\"inferSchema\", True).option(\"sep\", \",\").load(\"/Volumes/workspace/default/mandy/baby_names/Baby_Names_2007_2009.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb258b22-1394-4f68-8146-94b0ef80ad43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.filter(df.County == \"Hall County\")\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3df2d7a9-658d-4c24-9f6f-4772b7d253d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df2 = df1.groupBy(\"Year\").count().show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01 - Spark Architecture",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
